### 1. Classification Task 
```{r, indent=indent2}
# read the dataset 
spam <- read_table2("spambase.tab", guess_max=2000)
# standardize each numerical attribute in the dataset.
# Each standardized column should have zero mean and unit variance.
spam <- spam %>%
mutate(y = factor(y, levels=c(0,1), labels=c("good", "spam"))) %>% # label as factors
mutate_at(.vars=vars(-y), .funs=scale) # scale others
# function that calculates misclassification error rate 
calc_error_rate <- function(predicted.value, true.value){
return(mean(true.value!=predicted.value))
}
# calculate the error rates to measure and compare classification performance
# keep track of error rates of all methods 
records = matrix(NA, nrow=3, ncol=2)
colnames(records) <- c("train.error","test.error")
rownames(records) <- c("knn","tree","logistic")
# split the data randomly into a test set and training set 
set.seed(1)
test.indices = sample(1:nrow(spam), 1000)
spam.train=spam[-test.indices,]
spam.test=spam[test.indices,]
# 10-fold cross validation 
nfold = 10
set.seed(1)
folds = seq.int(nrow(spam.train)) %>% ## sequential obs ids
cut(breaks = nfold, labels=FALSE) %>% ## sequential fold ids
sample ## random fold ids
```

#### K Nearest Neighbor Method 
Use 10-fold cross validation to select the best number of neighbors best.kfold out of six values of k in kvec = c(1, seq(10, 50, length.out=5)). Use the folds defined above and use the following do.chunk definition in your code. Again put set.seed(1) before your code. What value of k leads to the smallest estimated test error?
```{r, indent=indent2, cache=TRUE}
do.chunk <- function(chunkid, folddef, Xdat, Ydat, k){
  train = (folddef!=chunkid)
  Xtr = Xdat[train,]
  Ytr = Ydat[train]
  Xvl = Xdat[!train,]
  Yvl = Ydat[!train]
## get classifications for current training chunks
  predYtr = knn(train = Xtr, test = Xtr, cl = Ytr, k = k)
## get classifications for current test chunk
  predYvl = knn(train = Xtr, test = Xvl, cl = Ytr, k = k)
  data.frame(train.error = calc_error_rate(predYtr, Ytr),
           val.error = calc_error_rate(predYvl, Yvl))
}
# Specify XTrain, YTrain
Xtrain = spam.train %>% select(-y) %>% scale(center=TRUE, scale = TRUE)
Ytrain = spam.train$y
# Specify XTest, YTest
Xtest= spam.test %>% select(-y) %>% scale(center=TRUE, scale = TRUE)
Ytest = spam.test$y
# set error.folds as a vector to save future validation errors 
error.folds=NULL
# The possible number of nearest neighbors to be considered 
# a total of 6 values -  1 10 20 30 40 50 
kvec = c(1, seq(10, 50, length.out=5)) 
# set seed since do.chunk() contains random component induced by knn()
set.seed(1)
# loop through the different number of neighbors 
for (j in kvec){
  tmp = ldply(1:nfold, do.chunk, # apply do.chunk() to each fold
              folddef=folds, Xdat=Xtrain, Ydat=Ytrain, k=j)
  # the necessary arguments for do.chunk
  tmp$neighbors=j # keep track of each value of neighbors 
  error.folds= rbind(error.folds,tmp) #combine results 
}
# Transform the format of error.folds for further convenience
errors = melt(error.folds, id.vars=c('neighbors'), value.name='error')
# choose the number of neighbors which minimizes validation error 
val.error.means= errors %>% 
  filter(variable=='val.error') %>%
  group_by(neighbors,variable) %>%
  summarise_each(funs(mean),error)%>%
  ungroup()%>%
  filter(error==min(error))
val.error.means
```
```{r, indent=indent2, cache=TRUE}
# Best number of neighbors out of the 6 values 
best.kfold = max(val.error.means$neighbors)
best.kfold #10
```

### 2. Training and Test Errors 
```{r, indent=indent2, cache=TRUE}
# compute training error and test error 
set.seed(1)
pred.Ytest = knn(train=Xtrain, test=Xtest, cl=Ytrain, k=best.kfold)
# error table for neighbors equal 10
errortable.10 <- error.folds %>% filter(neighbors==10)
# check if train error is the just average of train.error for all neighbors=10
train.error = mean(errortable.10$train.error)
test.error <- calc_error_rate(pred.Ytest, Ytest)
records[1,1] <- train.error 
records[1,2] <- test.error
records
```


(Controlling Decision Tree Construction) Function tree.control specifies options for tree construction:set minsize equal to 5 (the minimum number of observations in each leaf) and mindev equal to 1e-5. See the help for tree.control for more information. The output of tree.control should be passed into tree function in the control argument. Construct a decision tree using training set spam.train, call the resulting tree spamtree. summary(spamtree) gives some basic information about the tree. How many leaf nodes are there? How many of the training observations are misclassified?
```{r, indent=indent2,cache=TRUE}
spamtree <- tree(y ~ ., data = spam.train, 
                 control = tree.control(nobs = nrow(spam.train), minsize = 5, mindev = 1e-5))
summary(spamtree)
```

```{r, cache=TRUE}
# prune tree until there are only 10 leaf nodes
draw.tree(prune.tree(spamtree, best = 10), cex=0.5, nodeinfo = TRUE, col = NULL)
```

```{r}
set.seed(1)
# K-fold cross validation 
cv.spamtree <- cv.tree(spamtree, rand=folds, FUN= prune.tree ,method="misclass") 
cv.spamtree
```

```{r, cache=TRUE}
# plotting misclassification function of tree size 
# "b" - for points and lines 
plot(cv.spamtree$size, cv.spamtree$dev/length(cv.spamtree),type = "b",
     xlab = "Tree Size", ylab = "CV Misclassification Rate")
best.size.cv = cv.spamtree$size[max(which(cv.spamtree$dev==min(cv.spamtree$dev)))]
abline(v=best.size.cv, lty=2)
```
```{r, indent=indent2, cache=TRUE}
# Best size 
best.size.cv #22
```
```{r, chache = TRUE}
# prune spamtree to size of best.size.cv
spamtree.pruned <- prune.misclass(spamtree, best=best.size.cv)
# Plot pruned tree
draw.tree(spamtree.pruned, cex=0.30, nodeinfo = TRUE, col=NULL)
plot(spamtree.pruned)
text(spamtree.pruned, pretty=0, col = "red", cex = 0.35)
title("Pruned tree of size 22")
```
```{r, indent=indent2, cache=TRUE}
# predict on test set 
pred.spamtree.pruned <- predict(spamtree.pruned, spam.test , type = "class")
# training error and test error using calc_error_rate()
train.error1 = mean(predict(spamtree.pruned, spam.train , type = "class")!=spam.train$y)
test.error1 <- calc_error_rate(pred.spamtree.pruned, Ytest)
records[2,1] <- train.error1
records[2,2] <- test.error1
records
```

$$
\begin{aligned}
p(z) &= {\frac{e^{z}}{1+e^{z}}}\\
let \hspace{0.2cm} p(z) &= y\\
y &= {\frac{e^{z}}{1+e^{z}}}\\
z &= {\frac{e^{y}}{1+e^{y}}}\\
z(1+e^{y}) &= e^{y}\\
z + ze^{y} &= e^{y}\\
z &= e^{y} - ze^{y}\\
z &= e^{y}(1-z)\\
{\frac{z}{1-z}} &= e^{y}\\
ln({\frac{z}{1-z}}) &= ln(e^{y})\\
ln({\frac{z}{1-z}}) &= y\\
therefore, \hspace{0.2cm} z(p) &= ln({\frac{p}{1-p}})
\end{aligned}
$$

$$
\begin{aligned}
logit(p(z)) = \beta_{0} + \beta_{1}x_{1} + 2\beta_{1}\\
e^{logit(p(z)) }= e^{\beta_{0} + \beta_{1}x_{1} + 2\beta_{1}}\\
Odds(z) = e^{\beta_{0} + \beta_{1}x_{1} + 2\beta_{1}}\\
Odds(z) = e^{\beta_{0} + \beta_{1}x_{1}} \times e^{2\beta_{1}}\\
\end{aligned}
$$

$$
\begin{aligned}
p(z) &= {\frac{e^{\beta_{0} + \beta_{1}x_{1}}}{1+e^{\beta_{0} + \beta_{1}x_{1}}}}\\
since \hspace{0.2cm} \beta_{1} \hspace{0.2cm}is \hspace{0.2cm}a \hspace{0.2cm}negative \hspace{0.2cm}value, \hspace{0.2cm}
p(z) &= {\frac{e^{\beta_{0} - \beta_{1}x_{1}}}{1+e^{\beta_{0} - \beta_{1}x_{1}}}}\\
p(z) &= {\frac{e^{\beta_{0}}\times e^{-\beta_{1}x_{1}}}{1+e^{\beta_{0}} \times e^{-\beta_{1}x_{1}}}}\\
when \hspace{0.2cm} x_{1} \rightarrow \infty, \hspace{0.2cm} e^{-\beta_{1}x_{1}} \approx 0 \\
so \hspace{0.2cm} p(z) &= {\frac{e^{\beta_{0}}\times 0}{1+e^{\beta_{0}} \times 0 }}\\
therefore \hspace{0.2cm} p(z) \approx 0
\end{aligned}
$$

$$
\begin{aligned}
p(z) &= {\frac{e^{\beta_{0} + \beta_{1}x_{1}}}{1+e^{\beta_{0} + \beta_{1}x_{1}}}}\\
since \hspace{0.2cm} \beta_{1} \hspace{0.2cm}is \hspace{0.2cm}a \hspace{0.2cm}negative \hspace{0.2cm}value, \hspace{0.2cm}
p(z) &= {\frac{e^{\beta_{0} - \beta_{1}x_{1}}}{1+e^{\beta_{0} - \beta_{1}x_{1}}}}\\
x_{1} \rightarrow -\infty \hspace{0.2cm} so, \hspace{0.2cm} p(z) &= {\frac{e^{\beta_{0} - (-\beta_{1}x_{1}})}{1+e^{\beta_{0} - (-\beta_{1}x_{1})}}}\\
and \hspace{0.2cm} p(z) &= {\frac{e^{\beta_{0} +\beta_{1}x_{1}}}{1+e^{\beta_{0} + \beta_{1}x_{1}}}}\\
p(z) &= {\frac{e^{\beta_{0}}\times e^{\beta_{1}x_{1}}}{1+e^{\beta_{0}} \times e^{\beta_{1}x_{1}}}}\\
when \hspace{0.2cm} x_{1} \rightarrow \infty, \hspace{0.2cm} e^{\beta_{1}x_{1}} \approx 9999999...(very\hspace{0.2cm} large\hspace{0.2cm} value) \\
so \hspace{0.2cm} p(z) &= {\frac{e^{\beta_{0}}\times 999999.....}{1+e^{\beta_{0}} \times 999999..... }}\\
therefore \hspace{0.2cm} p(z) \approx 1
\end{aligned}
$$


```{r, indent=indent2}
# create a model using glm 
glm_spamtree <- glm(y~.,data = spam ,family = "binomial")
#kable(summary(glm_spamtree)$coefficients, digits=3)
```
```{r, indent=indent2, cache=TRUE}
# fit training values 
fitted_val.train <- predict(glm_spamtree,spam.train, type="response")
#fitted_val.train
```
```{r, indent=indent2, cache=TRUE}
# confusion matrix 
err.glm.train <- table(Truth=spam.train$y,Prediction=ifelse(fitted_val.train>0.5,"spam", "good"))
#err.glm.train 
```
```{r, indent=indent2, cache=TRUE}
# predict on test set
fitted_val.test <- predict(glm_spamtree,spam.test, type="response")
# confusion matrix 
err.glm.test <- table(Truth=spam.test$y,Prediction=ifelse(fitted_val.test>0.5,"spam", "good"))
#err.glm.test 
```
```{r, indent=indent2, cache=TRUE}
# training error for glm model 
train.glm.err <-  1- sum(diag(err.glm.train))/sum(err.glm.train)
# testing error for glm model 
test.glm.err <-  1- sum(diag(err.glm.test))/sum(err.glm.test)
# saving the errors in the matrix
records[3,1] <- train.glm.err
records[3,2] <- test.glm.err 
records
```
